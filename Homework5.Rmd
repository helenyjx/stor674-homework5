---
title: "Homework 5: Version Control, Containerization, and HPC"
author: "STOR 674 Jiaxin Ying"
date: "Due: 11/21/2025"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: united
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

```{r, include=FALSE}
knitr::opts_chunk$set(cache=TRUE, autodep=TRUE, cache.comments=TRUE)
```

# Overview

This homework will test your knowledge of version control with Git/GitHub, containerization with Docker, and high-performance computing with Apptainer and Slurm. You will:

1. Answer conceptual questions about Git and GitHub
2. **Create a GitHub repository and version control your Docker image build process (with branching and merging)**
3. Build a Docker image for the Linux environment and push it to Docker Hub
4. Download and run the image on Longleaf using Apptainer and Slurm

**Note:** You may be working on macOS or Windows, but you'll be building Linux containers that will run on Longleaf's Linux HPC environment.

**Total Points: 100**

**Important:** You will need to submit:
- A PDF/HTML version of this completed Rmd file with your answers
- A link to your GitHub repository
- A link to your Docker Hub image
- Your Slurm job script
- Screenshot/output of your Slurm job completion


GitHub repository:https://github.com/helenyjx/stor674-homework5

Docker Hub image: https://hub.docker.com/r/helenyjx24/compute-bench

---

# Part 1: Git and GitHub Concepts (20 points)

## Question 1.1: Understanding Commits (5 points)

**a)** (3 points) What does a commit do in Git? Explain what information is stored in a commit.

**Answer:**

A commit in Git is a snapshot of the project’s files at a specific point in time. Each commit records changes made to the repository, allowing developers to track history, revert to earlier versions, and collaborate efficiently.  A commit stores the following information:  

- **File snapshot:** The exact content of files that were added, modified, or deleted.  
- **Metadata:** The author’s name and email, date, and time of the commit.  
- **Parent commits:** References to one or more previous commits (used to form the project’s version history graph).  
- **Commit message:** A short description explaining the purpose of the change.  

In short, a commit acts like a save point that records both the state and context of the repository at that moment.  

---

**b)** (2 points) Why is it important to write descriptive commit messages? Provide an example of a good commit message and a bad commit message.

**Answer:**

Descriptive commit messages make it easier for collaborators—and your future self—to understand what changed and why. They improve project readability, simplify debugging, and help identify when and where a particular feature or bug fix was introduced.  

- **Good commit message:**  
  `Add Dockerfile and initial environment setup for Linux container build`  
   Clearly describes what was done and its purpose.  

- **Bad commit message:**  
  `fixed stuff`  
   Too vague; gives no context about the specific change or reason.
  
## Question 1.2: Branching in Git (10 points)

**a)** (5 points) Explain how branching works in Git. What happens when you create a new branch? What command would you use to create a new branch called `feature-analysis` and switch to it?

**Answer:**

Branching in Git allows you to diverge from the main development line and work on features, fixes, or experiments in isolation. When you create a new branch, Git creates a pointer to a specific commit, allowing multiple lines of development to exist simultaneously without interfering with each other.

**What happens when create a new branch:**

1. A new branch reference is created that points to the current commit
2. The branch is stored as a simple pointer (typically 40-byte SHA-1 hash reference)
3. Your working directory and staging area remain unchanged initially
4. The HEAD pointer can then be switched to this new branch
5. Subsequent commits on the new branch create a separate history without affecting the original branch

This creates a diverging commit history where each branch maintains its own sequence of commits while sharing a common ancestor commit.

**Command to Create and Switch to `feature-analysis`**

```bash
git checkout -b feature-analysis
```

After running this command, we are now on the `feature-analysis` branch and any commits make will be recorded on this branch, leaving the original branch (typically `main` or `master`) unchanged.

---

**b)** (5 points) Git branching is often described as "super lightweight" compared to other version control systems. Explain why Git branching is lightweight. (Hint: Think about how Git stores branches and what happens under the hood when you create a branch.)

**Answer:**

Git branching is considered super lightweight compared to other version control systems (like SVN or older systems) because of how Git fundamentally stores and manages branches under the hood.

**Key reasons for lightweight branching:**

1. **Branches are just pointers, not copies:** When create a branch in Git, it doesn't create a full copy of all files and the entire repository. Instead, it simply creates a small pointer (a 40-character SHA-1 hash) that references a specific commit. This pointer is typically stored as a few bytes in the `.git/refs/heads/` directory, making branch creation essentially instant.

2. **Commits are immutable snapshots:** Git uses a directed acyclic graph (DAG) of commits where each commit contains references to its parent(s). Multiple branches can point to commits that share common ancestors without duplication. Git doesn't need to store multiple copies of the repository content—all branches reference the same underlying objects (blob, trees, and commits) stored in the `.git/objects/` directory.

3. **No network overhead:** Creating a local branch is a purely local operation. Git doesn't need to contact a server or perform any network operations, making branch creation instantaneous (microseconds).

4. **Minimal disk space:** Since branches are just references, creating 100 branches takes up virtually no additional disk space compared to creating one branch. Each branch reference is only 40 bytes of text representing the commit hash.

5. **Efficient storage with delta compression:** Git stores objects efficiently using delta compression and content-addressable storage. Multiple branches pointing to common commits naturally share the same underlying data objects.

In older version control systems like SVN, creating a branch typically involves copying the entire directory structure on the server, which is time-consuming and resource-intensive. In Git, the operation is instant because we're only creating a small reference file. This lightweight nature makes Git's workflow fundamentally different—branching is so cheap that it encourages frequent branching for experimentation, feature development, and bug fixes without performance concerns.

## Question 1.3: Merging Branches (5 points)

**a)** (3 points) What is the purpose of merging branches? Describe the steps you would take to merge a branch called `feature-analysis` into the `main` branch.

**Answer:**

Merging branches serves several key purposes:

- **Isolation of work**: Developers can work on features independently without affecting the main codebase
- **Code review**: Changes can be reviewed and tested before integration
- **Parallel development**: Multiple features can be developed simultaneously
- **Version control**: Maintains a clear history of when and how features were integrated

Follow these steps to merge the feature branch into main:

**Step 1: Ensure your local repository is up to date**
```
git fetch origin
```

**Step 2: Switch to the main branch**
```
git checkout main
```

**Step 3: Pull the latest changes from main**
```
git pull origin main
```

**Step 4: Switch to the feature-analysis branch and ensure it's up to date**
```
git checkout feature-analysis
git pull origin feature-analysis
```

**Step 5: Return to main and merge the feature branch**
```
git checkout main
git merge feature-analysis
```

**Step 6: Resolve any merge conflicts (if they occur)**
- Open conflicted files and manually resolve conflicts
- Mark files as resolved: `git add <filename>`
- Complete the merge: `git commit -m "Merge feature-analysis into main"`

**Step 7: Push the merged changes to the remote repository**
```
git push origin main
```

---

**b)** (2 points) What is a merge conflict and when does it occur?

**Answer:**

A merge conflict occurs when Git cannot automatically reconcile differences between two branches during a merge operation. It happens when the same lines of code have been modified differently in each branch, making it impossible for Git to determine which version should be kept. The conflicting sections are marked in the file with conflict markers (`<<<<<<<`, `=======`, `>>>>>>>`), indicating the competing changes that need manual resolution.

Merge conflicts arise in specific situations:

**Simultaneous edits to the same file**: When two branches modify the same lines in the same file, Git cannot automatically decide which changes to keep.

**Changes to the same function or method**: If different branches alter the same function in incompatible ways, a conflict results.

**Deletion vs. modification**: When one branch deletes a file that another branch modifies, creating ambiguity about the intended state.

**Conflicting line additions**: When both branches add different content at the same location in a file.

**Merge after long divergence**: Branches that have developed independently for extended periods are more likely to have overlapping changes.

# Part 2: Docker Image Creation and Deployment with Version Control (50 points)

In this section, you will create a Docker image that can run the `compute_bench.py` script (which you used in Homework 2), which benchmarks CPU/GPU performance using PyTorch. **You will version control the entire process using Git and GitHub, practicing branching and merging workflows.**

**Important Note on Operating Systems:** You may be working on macOS or Windows, but Docker containers run Linux by default. You will be building a **Linux-based container** that will run on Longleaf (which is also Linux). Docker handles the cross-platform compatibility automatically, so your Linux container built on macOS/Windows will work seamlessly on Longleaf's Linux environment.

## Question 2.0: GitHub Repository Setup (5 points)

Before building your Docker image, you will set up version control for your project.

**a)** (1 points) Create a new GitHub repository called `stor674-homework5` (or similar name). Initialize it with a README. Provide the GitHub repository URL.

**GitHub Repository URL:**

https://github.com/helenyjx/stor674-homework5

  ![](1.png)

**b)** (2 points) Clone the repository to your local machine, add the provided files (`compute_bench.py`, this `Homework5.Rmd`), and make your initial commit. What commands did you use?

**Answer:**

```{bash}
# 1️⃣ Make sure inside the repo folder
cd ~/Desktop/Homework5/stor674-homework5

# 2️⃣ Copy the two files from your Homework5 folder into this repo folder
cp ../compute_bench.py .
cp ../Homework5.Rmd .

# 3️⃣ Confirm that the files are now inside your repo folder
ls

# 4️⃣ Stage the new files for commit
git add compute_bench.py Homework5.Rmd

# 5️⃣ Commit the changes
git commit -m "Initial commit: add compute_bench.py and Homework5.Rmd"

# 6️⃣ Push the changes to your GitHub repository
git push origin main
```

![](2.png)

**c)** (2 points) Create a new branch called `docker-build` where you will develop your Dockerfile. What command did you use? Why is it good practice to use a separate branch for development instead of working directly on `main`?

**Answer:**

```bash
# Command to create and switch to a new branch called docker-build
git checkout -b docker-build
```
![](3.png)

**Explanation:**

It is good practice to use a separate branch for development because:

It isolates changes, preventing unstable code from breaking the main project.

It allows for parallel development, so multiple features or fixes can be worked on simultaneously.

It enables code review and testing through pull requests before merging into the main branch.

It helps maintain a clean and stable main branch that always reflects production-ready code.

## Question 2.1: Understanding compute_bench.py (5 points)

**a)** (3 points) Read the `compute_bench.py` script. What does this script do? What is its main purpose?

**Answer:**

The `compute_bench.py` script is a simple performance benchmarking tool that measures the computational speed of performing large-scale tensor operations on both CPU and GPU using the PyTorch library.

Its main purpose is to compare the runtime efficiency of CPU versus GPU for numerical computations and to verify whether GPU acceleration is available and working properly on the system.

Specifically, the script:

1. **Imports PyTorch and time modules** to perform and time computations.  

2. **Defines a function** `run_computation(n, device)` that:

   - Generates `n` random numbers from a normal distribution.
   - Raises them to the fourth power (`x = torch.randn(n, device=device) ** 4`).
   - Measures how long the operation takes.
   - Synchronizes GPU operations to ensure accurate timing when using CUDA.
   
3. **Runs benchmarks** on two data sizes (`10^7` and `10^8` elements) for both CPU and GPU (if available).

4. **Prints the computation times** for each case, showing how much faster the GPU performs compared to the CPU.

5. **Generates and prints** a small sample of 10 random numbers as an example output.

6. **Saves the sample tensor** to a file named `mydata.pt`, similar to R’s `save.image()` function.

In summary, this script’s main goal is to benchmark CPU vs GPU computation times for large tensor operations and to confirm that PyTorch can properly use GPU acceleration on the system.

**b)** (2 points) What Python packages does `compute_bench.py` require?

**Answer:**

The `compute_bench.py` script requires the following Python packages:

1. **torch** — the PyTorch library used for tensor creation, random number generation, mathematical operations, GPU acceleration (via CUDA), and saving data (`torch.save`).
2. **time** — a built-in Python module used to measure computation time between the start and end of each operation.

## Question 2.2: Create a Dockerfile (10 points)

Create a Dockerfile that:
- Uses an appropriate **Linux-based** base image with Python 3.9 or later
- Installs the required Python packages (PyTorch with CUDA support for GPU computing)
- Copies `compute_bench.py` into the container
- Sets the default command to run the script

**Important Considerations:**

- **Operating System**: Even if you're on macOS or Windows, Docker will build a Linux container. Use Linux base images (e.g., `python:3.9-slim` is based on Debian Linux).

- **CUDA Support**: Longleaf has NVIDIA GPUs. To enable GPU support in your container:
  - Option 1: Use official PyTorch image with CUDA: `pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime`
  - Option 2: Install PyTorch with CUDA support: `pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118`
  - Note: The container itself doesn't need NVIDIA drivers (Longleaf provides those), but PyTorch needs to be CUDA-aware.

- **Testing Locally**: If your computer doesn't have an NVIDIA GPU, the container will still build and run (it will just use CPU). On Longleaf with GPU nodes, it will automatically detect and use the GPU.

**Instructions:**

1. Make sure you're on the `docker-build` branch
2. Create a file named `Dockerfile` in your repository
3. Write the Dockerfile content below:

```dockerfile
# ===== Dockerfile for compute_bench.py =====
# Use official PyTorch image with CUDA support (Python 3.9+)
FROM --platform=linux/amd64 pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime

# Set working directory inside the container
WORKDIR /app

# Copy the compute_bench.py script into the container
COPY compute_bench.py /app/compute_bench.py

# Ensure Python prints output directly to console
ENV PYTHONUNBUFFERED=1

# Default command to run the benchmark script
CMD ["python", "/app/compute_bench.py"]
```

**Grading Criteria:**
- Appropriate Linux base image selection (2 points)
- CUDA-enabled PyTorch installation (4 points)
- Proper file copying (2 points)
- Correct CMD or ENTRYPOINT (2 points)

## Question 2.3: Build and Test Docker Image (10 points)

**a)** (3 points) What command did you use to build your Docker image? Include the full command and explain each part.

**Answer:**

```bash
# Command used to build the Docker image
docker build --platform=linux/amd64 -t compute-bench .
```

**Explanation:**

`docker build` — builds a Docker image from a Dockerfile in the current directory.

`--platform=linux/amd64` — ensures compatibility with Longleaf’s GPU nodes, which use x86-64 architecture (necessary because my Mac uses ARM64).

`-t compute-bench` — tags the image with the name compute-bench for easy reference.

`.` — specifies the build context (current directory where the Dockerfile and source files are located).


**b)** (4 points) What command did you use to run your Docker image locally to test it? Include the output you received.

**Answer:**

```bash
# Command used to run the Docker container locally (CPU test)
docker run --rm --platform=linux/amd64 compute-bench
```

**Output:**

```
# Paste the output here
No GPU available, running on CPU only

CPU Computations:
Time for 10,000,000 elements: 0.2418 seconds
Time for 100,000,000 elements: 2.2797 seconds

Small sample of 10 random numbers:
tensor([-0.1326, -1.5500,  1.1859,  1.5597,  0.7008, -0.4011, -1.1648,  0.1153,
        -0.3273, -0.3363])

Saved data to mydata.pt
```

**c)** (3 points) Were there any issues you encountered during the build or test? How did you resolve them?

**Answer:**

![](4.png)
![](5.png)

Yes. When building the image on my Apple Silicon Mac (ARM64), I received a warning:

"InvalidBaseImagePlatform: Base image pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime was pulled with platform "linux/amd64", expected "linux/arm64"`"

This occurred because the PyTorch CUDA base image only supports x86-64 (amd64) architecture, while my system uses ARM64.

Resolution: I rebuilt the image using the platform flag to force the correct architecture: `docker build --platform=linux/amd64 -t compute-bench .`

This allowed the image to build successfully and ensured compatibility with Longleaf’s GPU nodes, which use the same x86-64 architecture.

## Question 2.4: Version Control Your Docker Build (10 points)

Now that you have a working Dockerfile, let's commit it and merge it into the main branch.

**a)** (3 points) On your `docker-build` branch, add and commit your Dockerfile with a descriptive commit message. What commands did you use?

**Answer:**

![](6.png)

```bash
# Ensure on the docker-build branch
git checkout docker-build

# Check the status to confirm the Dockerfile is untracked or modified
git status

# Add the Dockerfile to the staging area
git add Dockerfile

# Commit the Dockerfile with a descriptive message
git commit -m "Added Dockerfile for compute_bench.py with PyTorch CUDA support"
```

**b)** (4 points) Switch to the `main` branch and merge the `docker-build` branch into it. What commands did you use? Paste the merge message or output.

**Answer:**

![](7.png)

```bash
# Step 1: Switch to the main branch
git checkout main

# Step 2: Pull the latest updates from the remote main branch (optional but good practice)
git pull origin main

# Step 3: Merge the docker-build branch into main
git merge docker-build
```

**Merge Output:**

```
# Paste merge output here
Updating 48e3e1f..8810fb5
Fast-forward
 Dockerfile | 15 +++++++++++++++
 1 file changed, 15 insertions(+)
 create mode 100644 Dockerfile
```

**c)** (3 points) Push your changes to GitHub. Verify that your repository now contains the Dockerfile on the main branch. What command did you use to push?

**Answer:**

![](8.png)

```bash
# Command to push the updated main branch to GitHub
git push origin main
```

**Verification:** Visit your GitHub repository in a web browser and confirm the Dockerfile is visible. ✓

![](9.png)
![](10.png)

## Question 2.5: Push to Docker Hub (10 points)

**a)** (3 points) Create a Docker Hub account (if you don't have one) and provide your Docker Hub username.

**Docker Hub Username:** helenyjx24


**b)** (4 points) Tag your image appropriately and push it to Docker Hub. What commands did you use?

**Answer:**

```bash
# Commands you used
# Step 1: Log in to Docker Hub
docker login

# Step 2: Tag the local image with your Docker Hub username and repository name
docker tag compute-bench helenyjx24/compute-bench:latest

# Step 3: Push the tagged image to Docker Hub
docker push helenyjx24/compute-bench:latest
```
![](11.png)

**c)** (3 points) Provide the full Docker Hub image URL/name that others can use to pull your image.

![](12.png)

**Image URL:** Format: username/imagename:tag

Image URL:
helenyjx24/compute-bench:latest

Full Docker Hub URL:
https://hub.docker.com/r/helenyjx24/compute-bench

---

# Part 3: Apptainer and Slurm on Longleaf (30 points)

In this section, you will download your Docker image using Apptainer on UNC's Longleaf cluster and submit a job using Slurm. Remember: your Linux container built on macOS/Windows will run seamlessly on Longleaf's Linux environment.

## Question 3.1: Understanding Apptainer (5 points)

**a)** (3 points) What is Apptainer (formerly Singularity) and why is it used on HPC systems instead of Docker?

**Answer:**

Apptainer (formerly known as Singularity) is an open-source container platform designed specifically for High-Performance Computing (HPC) environments. It allows users to package their entire software environment—including applications, dependencies, and libraries—into a single portable image file that can be executed reproducibly across systems.

Apptainer is preferred over Docker on HPC systems because:

1. **Security:**  
   Docker requires root (administrator) privileges, which can pose a security risk on shared clusters.  
   Apptainer runs containers entirely in user space, so users do not need elevated permissions.

2. **HPC Compatibility:**  
   It integrates seamlessly with Slurm, MPI, and GPU drivers on clusters like Longleaf.  
   Users can access host files, directories, and GPUs directly inside the container.

3. **Reproducibility and Portability:**  
   Apptainer uses immutable `.sif` (Singularity Image Format) files, ensuring the same environment runs consistently across different systems without modification.

---

**b)** (2 points) What does "Bring Your Own Environment" (BYOE) mean in the context of HPC and containers?

**Answer:**

BYOE means that researchers can create and package their own software environments locally, for example, using Docker on macOS or Windows—and then run the exact same environment on an HPC system like Longleaf using Apptainer. This approach eliminates dependency conflicts and ensures full reproducibility. In practice, users build a Docker image (e.g., with Python, PyTorch, and CUDA) on their local machine, convert or pull it into Apptainer on Longleaf, and then execute it through Slurm without needing to install packages directly on the cluster.

## Question 3.2: Convert Docker Image to Apptainer (10 points)

**a)** (5 points) Log into Longleaf and use Apptainer to pull your Docker image from Docker Hub. What command did you use?

**Answer:**

```bash
# Command to pull/convert Docker image to Apptainer
# Step 1: Log in to UNC Longleaf from local terminal
ssh jiaxiny@longleaf.unc.edu

# When prompted, enter ONYEN password and 2FA code.After successful login, prompt look like:[jiaxiny@longleaf-login5 ~]$

# Step 2: Load the Apptainer module (formerly Singularity)
module load apptainer

# Step 3: Pull and convert your Docker image from Docker Hub into a local Apptainer (.sif) image
apptainer pull compute-bench.sif docker://helenyjx24/compute-bench:latest
```

![](13.png)

**b)** (3 points) What is the name of the Apptainer image file (.sif) that was created?

**Answer:**

```
# Filename here:
compute-bench.sif
```

**c)** (2 points) Test your Apptainer image interactively. What command did you use to run it?

**Answer:**

```bash
# Command to run Apptainer image
# Run the Apptainer image interactively to test it on Longleaf
apptainer run compute-bench.sif
```
![](14.png)

## Question 3.3: Create Slurm Job Script (12 points)

Create a Slurm job script that runs your containerized `compute_bench.py` using Apptainer.

**Hint:** If you want to test with GPU support on Longleaf, you'll need to:
- Request a GPU partition (e.g., `#SBATCH -p gpu`)
- Request GPU resources (e.g., `#SBATCH --gres=gpu:1`)
- Your CUDA-enabled PyTorch in the container will automatically use the GPU!

**Instructions:**

1. Create a file named `run_compute_bench.sh` in your GitHub repository
2. Include appropriate Slurm directives (partition, time, memory, etc.)
3. Load necessary modules (if needed)
4. Run the Apptainer container

**Your Slurm Script:**

```bash
#!/bin/bash
#SBATCH --job-name=compute-bench
#SBATCH --partition=gpu
#SBATCH --qos=gpu_access
#SBATCH -N 1
#SBATCH --ntasks=1
#SBATCH --gres=gpu:1
#SBATCH --mem=16G
#SBATCH --time=00:20:00
#SBATCH --output=slurm-%j.out

# ---- Set up environment ----
module purge
module load apptainer

# Move to the job submission directory
cd "$SLURM_SUBMIT_DIR"

# Run the containerized application
apptainer exec --nv compute-bench.sif python /app/compute_bench.py > slurm-${SLURM_JOBID}.pyout 2>&1

# Append Python output to main log file
cat slurm-${SLURM_JOBID}.pyout >> slurm-${SLURM_JOBID}.out
```

**Grading Criteria:**
- Appropriate Slurm directives (#SBATCH) (4 points)
- Correct Apptainer run command (6 points)
- Output redirection and job organization (2 points)

## Question 3.4: Submit, Verify, and Version Control (3 points)

**a)** (1 point) What command did you use to submit your job to Slurm?

**Answer:**

```bash
# Command used to submit the job to Slurm
sbatch run_compute_bench.sh
```

**b)** (2 points) Provide the output of your job. Paste the contents of your Slurm output file (e.g., `slurm-jobid.out`). Also, add your Slurm script (`run_compute_bench.sh`) to your GitHub repository and push it.

**Job Output:**

```
# Paste your job output here
GPU available: NVIDIA GeForce GTX 1080

CPU Computations:
Time for 10,000,000 elements: 0.2380 seconds
Time for 100,000,000 elements: 1.7088 seconds

GPU Computations:
Time for 10,000,000 elements: 6.1845 seconds
Time for 100,000,000 elements: 0.0061 seconds

Small sample of 10 random numbers:
tensor([ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229, -0.1863,  2.2082, -0.6380,
         0.4617,  0.2674])

Saved data to mydata.pt
```

**GitHub Verification:** ✓ Pushed `run_compute_bench.sh` to repository

![](17.png)

**c)** (BONUS: +2 points) Include a screenshot showing your job in the Slurm queue or completed job information using `squeue` or `sacct`. Also show that your job successfully utilized a GPU (if you requested one).

![](15.png)
![](16.png)
---

# Part 4: Reflection and Best Practices (Optional - Extra Credit: 5 points)

**Question 4.1:** Reflect on the workflow you just completed (Git → Docker → HPC). How does this approach improve reproducibility in computational research? What are some advantages and potential challenges?

**Answer:**

The Git → Docker → HPC workflow creates a fully reproducible, portable, and transparent research pipeline by capturing every stage of the computational environment:

1. **Git for version control:**  
   Git ensures that all code, scripts, and documentation are versioned and traceable. Researchers can roll back to specific commits, collaborate efficiently, and maintain clear provenance of changes over time.

2. **Docker for environment encapsulation:**  
   Docker containers freeze software dependencies—such as Python, PyTorch, and CUDA—into a single build specification (the Dockerfile). This guarantees that anyone who rebuilds or pulls the image will run code under identical library versions and operating-system settings.

3. **HPC (Apptainer on Longleaf) for scalable execution:**  
   By running the same containerized environment on a high-performance cluster, computations can be scaled to large data or GPU workloads without reinstalling software. Apptainer bridges the gap between local Docker images and secure HPC systems, ensuring consistent runtime behavior.

**Advantages:**

- Enhances **reproducibility** across machines, collaborators, and time.  
- Promotes **portability**, allowing the same workflow to run locally, in the cloud, or on HPC nodes.  
- Simplifies **dependency management**—no more “works on my machine” issues.  
- Improves **collaboration and transparency**, since all components are documented and version-controlled.

**Potential Challenges:**

- **Learning curve:** Understanding Dockerfiles, Apptainer, and Slurm scripting requires technical effort.  
- **Storage and build size:** Large container images (e.g., with CUDA) can consume significant disk space.  
- **Platform differences:** Architecture mismatches (ARM vs x86) may need extra flags during builds.  
- **Cluster policies:** Some HPCs restrict Docker usage, requiring conversion to Apptainer images.

Overall, this integrated workflow embodies best practices in reproducible computational science—linking code, environment, and computation so that results can be reliably re-created by anyone, anywhere in the future.

---

# Submission Checklist

Before submitting, make sure you have:

- [ ] Completed all questions in Part 1 (Git/GitHub concepts)
- [ ] **Created a GitHub repository with all your project files**
- [ ] **Practiced branching and merging in your Git workflow**
- [ ] Created a Dockerfile with CUDA support for GPU computing
- [ ] Built and tested your Docker image locally (Linux container on macOS/Windows)
- [ ] Pushed your image to Docker Hub
- [ ] Provided your Docker Hub image URL
- [ ] Created a Slurm job script
- [ ] Successfully ran your job on Longleaf
- [ ] **Pushed all files (Dockerfile, Slurm script, completed Rmd) to GitHub**
- [ ] Included all output and screenshots
- [ ] Compiled this Rmd file to HTML or PDF

**Submission Instructions:**

1. **Ensure your GitHub repository contains:**
   - `Dockerfile`
   - `compute_bench.py`
   - `run_compute_bench.sh` (Slurm script)
   - `Homework5.Rmd` (completed)
   - Evidence of branching/merging in commit history
   
2. Submit the knitted HTML/PDF file on Canvas
3. **Submit the link to your GitHub repository on Canvas (REQUIRED)**
4. Submit the link to your Docker Hub image on Canvas

---

# Grading Rubric

| Section | Points |
|---------|--------|
| Part 1: Git and GitHub Concepts | 20 |
| Part 2: Docker with Version Control (includes branching/merging) | 50 |
| Part 3: Apptainer and Slurm on Longleaf | 30 |
| **Total** | **100** |
| Extra Credit (Part 4: Reflection) | +5 |
| Extra Credit (Part 3.4c: GPU screenshot) | +2 |
| **Maximum Possible** | **107** |
